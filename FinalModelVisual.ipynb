{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyproj import Proj\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from argparse import ArgumentParser\n",
    "from final_data_clean import *\n",
    "from merge_pluto_finance_new import *\n",
    "from predict_price_increase import *\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_target_var(data, target_name):\n",
    "    '''\n",
    "    Separates X and y variables for data.\n",
    "    Args:\n",
    "        data: Pandas dataframe containing all data.\n",
    "        target_name: column name of target variable\n",
    "    Returns:\n",
    "        X: Pandas dataframe with training features\n",
    "        y: Target variable for X as Pandas series.\n",
    "    '''\n",
    "    # Convert int64 to float64\n",
    "    data = data.astype(float)\n",
    "    # Drop NaN for crucial columns\n",
    "    data = data.replace({np.Inf:np.nan, -np.Inf:np.nan})\n",
    "    data = data.dropna(how = 'any', subset = [target_name])\n",
    "    # Split data into X and y\n",
    "    X = data.drop(target_name, axis=1)\n",
    "    y = data.loc[:,target_name]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_for_model(data_path = \\\n",
    "        'bronx_brooklyn_manhattan_queens_statenisland_2003_2016.csv'):\n",
    "    df = pd.read_csv(data_path, low_memory = True)\n",
    "    # drop columns that are not needed or are redundant\n",
    "    df = drop_cols(df, ['sale_date', 'sale_price'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_RF(X_train, X_test, y_train, y_test):\n",
    "    RF_reg_final = RandomForestRegressor(n_estimators=100, n_jobs = -1)\n",
    "    RF_reg_final.fit(X_train, y_train)\n",
    "    predicted = RF_reg_final.predict(X_test)\n",
    "    percent_diff = 100*(np.abs(predicted - y_test).astype(float) / y_test)\n",
    "    acc = 100 * (sum(i < 10. for i in percent_diff)/ len(percent_diff))\n",
    "    print('Mean squared error for Random Forest model: ', mean_squared_error(y_test, RF_reg_final.predict(X_test)))\n",
    "    print('\\nAccuracy (within 10% of true value): ', acc)\n",
    "    return RF_reg_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for Random Forest model:  17127.1274738\n",
      "\n",
      "Accuracy (within 10% of true value):  27.3122133463\n"
     ]
    }
   ],
   "source": [
    "data = get_data_for_model(\"data/merged/queens_2003_2016.csv\")\n",
    "X, y = create_target_var(data, 'price_per_sqft')\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "X_train, X_test = fill_na(X_train, X_test)\n",
    "X_train, X_test = normalize(X_train, X_test)\n",
    "random_forest = fit_RF(X_train, X_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bbl': 0.010076258581288021,\n",
       " 'bldgclass_G': 0.017520486379875754,\n",
       " 'bldgclass_N': 0.014502305336699321,\n",
       " 'bldgclass_S': 0.0048488976423289431,\n",
       " 'bldgclass_V': 0.0049907664721226992,\n",
       " 'bldgdepth': 0.17060307888329804,\n",
       " 'bsmtcode': 0.11907628659200706,\n",
       " 'builtcode': 0.0078152940275057169,\n",
       " 'comarea': 0.006845862332881111,\n",
       " 'easements': 0.0069429897495633134,\n",
       " 'extension': 0.010594219998793085,\n",
       " 'histdist': 0.0065445577770142215,\n",
       " 'irrlotcode': 0.14309928652490603,\n",
       " 'landmark': 0.0088649464793439433,\n",
       " 'latitude': 0.010757607393473421,\n",
       " 'longitude': 0.01310177063661945,\n",
       " 'lotfront': 0.0069933263118431947,\n",
       " 'numbldgs': 0.095527006659086963,\n",
       " 'numfloors': 0.019020032852378046,\n",
       " 'out_of_school_youth_centers_dist_mv': 0.0049046382057501194,\n",
       " 'resarea': 0.024536905878914488,\n",
       " 'schooldist_25': 0.0095026853328420025,\n",
       " 'schooldist_29': 0.0050866929096178093,\n",
       " 'summer_youth_employment_centers_dist_mv': 0.0081286787768381479,\n",
       " 'unitsres': 0.0080964346795241726,\n",
       " 'unitstotal': 0.0047211113621057899,\n",
       " 'yearbuilt': 0.1760231807665521}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance =  random_forest.feature_importances_\n",
    "indices = np.argsort(feature_importance)[::-1][:27]\n",
    "\n",
    "feature_dct = {}\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(27):\n",
    "    feature_dct[data.ix[:,1:].columns.values[indices][f]] = feature_importance[indices[f]]\n",
    "feature_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "\n",
    "feature_dct = OrderedDict(sorted(feature_dct.items(), key=itemgetter(1), reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_features = feature_dct.copy()\n",
    "pos_features = feature_dct.copy()\n",
    "\n",
    "#Use correlation matrix to determine which features are negatively correlated with our target variable\n",
    "negs = ['date','sentyr','district_74','monsex','state_CA','crimetype_immigration',\n",
    "       'crime_9.0','crime_14.0','newcit','crimetype_drug - trafficking','district_70',\n",
    "       'MLB_Allowed_GameNightBefore','MLB_Scored_GameNightBefore','neweduc_5',\n",
    "       'state_AZ']\n",
    "for key in neg_features.keys():\n",
    "    if key in negs:\n",
    "        neg_features[key] = -neg_features[key]\n",
    "    else:\n",
    "        neg_features[key] = 0\n",
    "for key in pos_features.keys():\n",
    "    if key in negs:\n",
    "        pos_features[key] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
