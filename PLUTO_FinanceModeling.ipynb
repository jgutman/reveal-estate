{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyproj import Proj\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn import model_selection as cross_validation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import collections\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"data/merged/bronx_brooklyn_manhattan_queens_statenisland_2003_2016.csv\"\n",
    "df = pd.read_csv(data_path, low_memory = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_dups = df.drop_duplicates()\n",
    "no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['bbl','zipcode','latitude','longitude']].to_csv(\"bbls_and_zips.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = df[df['year_built'] != df['yearbuilt']]\n",
    "x[x['year_built'] == 0.0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['gross_sqft_pluto','sale_price','price_per_sqft']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df['price_per_sqft'] != 0.0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df['price_per_sqft'] >= 10]\n",
    "df = df[df['price_per_sqft'] <= 5000]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = collections.Counter(df['price_per_sqft'].astype(int))\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outliers = df.loc[df['price_per_sqft'].astype(int).isin([1,2,3,4,5,6912,7655,7949,10315,12089,14568])]\n",
    "outliers[['latitude','longitude','price_per_sqft','sale_price','year_built','sale_date']].to_csv(\"outliers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#output distribution of target variable to visualize in Tableau\n",
    "import csv\n",
    "x = df['price_per_sqft']\n",
    "count = collections.Counter(x.astype(int))\n",
    "with open(\"price_per_sqft_counts.csv\",'w') as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow(['Price Per Sqft', 'Frequency'])\n",
    "    for key, count in count.items():\n",
    "        writer.writerow([key, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output distribution of sale price to visualize in Tableau\n",
    "import csv\n",
    "x = df['sale_price']\n",
    "count = collections.Counter(x.astype(int))\n",
    "with open(\"sale_price_counts.csv\",'w') as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow(['Sale Price', 'Frequency'])\n",
    "    for key, count in count.items():\n",
    "        writer.writerow([key, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drop_cols(data, cols):\n",
    "    return data.drop(cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = drop_cols(df, ['zonemap','sale_date','sale_price','year_built'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "def split_data(data):\n",
    "    '''\n",
    "    Splits data into training and test sets (0.8/0.2)\n",
    "        Args: \n",
    "            data: Pandas dataframe\n",
    "        Returns:\n",
    "            data_train: Pandas dataframe used for training\n",
    "            data_test: Pandas dataframe used for testing\n",
    "    \n",
    "    '''\n",
    "    #Convert 'int64' into float; otherwise, sklearn throws a warning message\n",
    "    columns = data.columns.values\n",
    "    non_float = []\n",
    "    for col in columns:\n",
    "        if data[col].dtype != np.float64:\n",
    "            non_float.append(col)\n",
    "    for col in non_float:\n",
    "        data[col] = data[col].astype(float)\n",
    "    #drop NaN for crucial columns\n",
    "    data= data.dropna(how = 'any', subset = ['price_per_sqft'])   \n",
    "    #Split the data\n",
    "    rs = model_selection.ShuffleSplit(train_size = 0.8, test_size=.2, random_state = 1, n_splits = 1)\n",
    "\n",
    "    for train, test in rs.split(data):\n",
    "        train_index = train\n",
    "        test_index = test\n",
    "    data_train = data.ix[train_index,:]\n",
    "    data_test = data.ix[test_index,:]\n",
    "    data_train.reset_index(drop=True, inplace=True)\n",
    "    data_test.reset_index(drop=True, inplace=True)\n",
    "    return data_train, data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train, data_test = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fill_na(data_train, data_test):\n",
    "    '''\n",
    "    Fills NaN values with the mean of the column. Note we have already created dummy variables\n",
    "    for columns with missing values.\n",
    "    \n",
    "    Args:\n",
    "        data_train: Pandas dataframe used for training.\n",
    "        data_test: Pandas dataframe used for testing.\n",
    "    Returns:\n",
    "        data_train: Pandas dataframe with no NaN values, ready for modeling.\n",
    "        data_test: Pandas dataframe with no NaN values, ready for testing.\n",
    "    \n",
    "    '''\n",
    "    data_train = data_train.apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "    data_test = data_test.apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train, data_test = fill_na(data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data_train.shape, data_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = list(data_train.columns.values) #Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('price_per_sqft')) #Remove b from list\n",
    "data_train = data_train[cols+['price_per_sqft']]\n",
    "data_test = data_test[cols+['price_per_sqft']]\n",
    "data_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data_train.drop(['public_recycling_bins_dist'], axis = 1)\n",
    "data_test = data_test.drop(['public_recycling_bins_dist'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = data_train.ix[:,:-1]\n",
    "y_train = data_train.ix[:,-1]\n",
    "X_test = data_test.ix[:,:-1]\n",
    "y_test = data_test.ix[:,-1]\n",
    "regr = linear_model.LinearRegression()\n",
    "#regr.fit(X_train, y_train)\n",
    "#mse = mean_squared_error(y_test, regr.predict(X_test))\n",
    "#print('Mean_squared_error', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RF_reg_final = RandomForestRegressor(n_estimators=100, n_jobs = -1)\n",
    "RF_reg_final.fit(X_train, y_train)\n",
    "print(mean_squared_error(y_test, RF_reg_final.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbls = []\n",
    "file = open(\"data/Queens Light Rail BBL.csv\", 'rb')\n",
    "for line in file:\n",
    "    bbls.append(line)\n",
    "bbls = [float(i) for i in bbls]\n",
    "bbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finance = pd.read_csv(\"finance_queens.csv\")\n",
    "finance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens = pd.read_csv(\"data/nyc_pluto_16v1/QN.csv\", low_memory = False)\n",
    "queens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings_2 = pd.read_csv(\"pluto_finance_test.csv\")\n",
    "buildings_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings_3 = pd.read_csv(\"data/merged/queens_2003_2016.csv\")\n",
    "buildings_3['price_per_sqft'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings_3 = buildings_3.drop_duplicates()\n",
    "buildings_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.bbl.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings_3.bbl.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings = pd.merge(queens, finance, how='right',\n",
    "        left_on='BBL', right_on = 'bbl')\n",
    "buildings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings_2 = buildings_2.drop_duplicates()\n",
    "buildings_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affected_properties = finance.loc[finance['bbl'].isin(bbls)]\n",
    "affected_properties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(X_test['bbl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_importance =  RF_reg_final.feature_importances_\n",
    "indices = np.argsort(feature_importance)[::-1][:27]\n",
    "\n",
    "feature_dct = {}\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(20):\n",
    "    feature_dct[X_test.columns.values[indices][f]] = feature_importance[indices[f]]\n",
    "feature_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "\n",
    "feature_dct = OrderedDict(sorted(feature_dct.items(), key=itemgetter(1), reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_dct.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train[['price_per_sqft'] + list(feature_dct.keys())].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_features = feature_dct.copy()\n",
    "pos_features = feature_dct.copy()\n",
    "\n",
    "#Use correlation matrix to determine which features are negatively correlated with our target variable\n",
    "negs = ['gross_sqft_pluto','unitstotal']\n",
    "for key in neg_features.keys():\n",
    "    if key in negs:\n",
    "        neg_features[key] = -neg_features[key]\n",
    "    else:\n",
    "        neg_features[key] = 0\n",
    "for key in pos_features.keys():\n",
    "    if key in negs:\n",
    "        pos_features[key] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test['predicted'] = RF_reg_final.predict(X_test)\n",
    "data_test['percent_difference'] = 100*(np.abs(data_test['predicted'] - data_test['price_per_sqft']).astype(float) / data_test['price_per_sqft'])\n",
    "data_test[['yearbuilt','price_per_sqft','predicted','percent_difference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = 100 * (data_test[data_test['percent_difference'] < 10.0].shape[0]/ data_test.shape[0])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"preliminary_results.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import merge_pluto_finance_new as mpf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queens_pluto = mpf.read_in_pluto([\"queens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_pluto.bbl.astype(int).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_finance = mpf.read_in_finance([\"queens\"], list(range(2003, 2017)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_finance.bbl.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(queens_finance.shape)\n",
    "print(queens_pluto.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(queens_pluto.bbl.dtype)\n",
    "print(queens_finance.bbl.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_dtm = read_in_dtm([\"queens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def read_in_dtm(boros, data_dir = 'data/dtm',\n",
    "        filename = 'DTM_0316_Condo_Units.csv'):\n",
    "    \"\"\"\n",
    "    Reads in the Digital Tax Map dataset and returns a dataframe with mapping\n",
    "    from borough and condo number to unit BBL for the specified boroughs.\n",
    "\n",
    "    Args:\n",
    "        list(string) boros: list of all the boroughs to pull dtm data for\n",
    "        string data_dir: a relative path as a string to folder containing the\n",
    "            dtm data in csv format\n",
    "        string filename: the name of the file containing the dtm condo unit data\n",
    "    Returns:\n",
    "        Pandas DataFrame\n",
    "    \"\"\"\n",
    "    columns = ['CONDO_BORO', 'CONDO_NUMB', 'UNIT_BLOCK',\n",
    "               'UNIT_LOT', 'UNIT_BBL', 'UNIT_DESIG']\n",
    "    boro_names = ['manhattan', 'bronx', 'brooklyn', 'queens', 'statenisland']\n",
    "    boro_codes = dict(zip(boro_names, range(1,6)))\n",
    "    dtm = pd.read_csv(os.path.join(data_dir, filename), usecols=columns)\n",
    "    dtm.columns = [col.strip().lower() for col in dtm.columns]\n",
    "    dtm = dtm.dropna(subset = ['unit_bbl', 'condo_boro', 'condo_numb'])\n",
    "    dtm.unit_bbl = dtm.unit_bbl.astype('int64')\n",
    "    dtm = dtm.loc[dtm.condo_boro.isin(\n",
    "        [boro_codes.get(boro) for boro in boros])]\n",
    "    return dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['CONDO_BORO', 'CONDO_NUMB', 'UNIT_BLOCK',\n",
    "               'UNIT_LOT', 'UNIT_BBL', 'UNIT_DESIG']\n",
    "data_dir = 'data/dtm'\n",
    "filename = 'DTM_0316_Condo_Units.csv'\n",
    "queens_dtm = pd.read_csv(os.path.join(data_dir, filename), usecols=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_dtm.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"data/open_nyc/subwaydist.csv\"\n",
    "subwaydist = pd.read_csv(filepath)\n",
    "filepath = \"data/open_nyc/some_dist_metrics.csv\"\n",
    "other_distances = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pd.unique(other_distances.bbl)) == other_distances.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pd.unique(subwaydist.bbl)) == subwaydist.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finance_condo_updated = mpf.get_finance_condo_lot(pluto = queens_pluto,\n",
    "        finance = queens_finance, dtm = queens_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finance_condo_updated.bbl_pluto.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_pluto.bbl.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buildings = pd.merge(queens_pluto, finance_condo_updated, how='right',\n",
    "        left_on='bbl', right_on = 'bbl_pluto',\n",
    "        suffixes=['_pluto', '_finance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings[\"price_per_sqft\"] = buildings[\"sale_price\"].astype('float64') / buildings[\"gross_sqft_pluto\"]\n",
    "buildings = buildings[ buildings[\"price_per_sqft\"].notnull()]\n",
    "buildings = buildings[ buildings[\"price_per_sqft\"] > 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings.bbl_pluto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings.bbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_pluto.bbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finance_condos_only.bbl_finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_finance.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_pluto.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_dtm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finance_condo_updated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(queens_finance.drop_duplicates().shape == queens_finance.shape)\n",
    "print(queens_pluto.drop_duplicates().shape == queens_pluto.shape)\n",
    "print(finance_condos_only.drop_duplicates().shape == finance_condos_only.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finance_condos_only.shape[0] + len(standard_bbls) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbl_mappings.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_finance.drop_duplicates(['bbl', 'sale_year']).shape == queens_finance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_finance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_finance.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queens_finance[\"sale_year\"] = [d.year for d in queens_finance.sale_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(finance_condo_updated.drop_duplicates().shape)\n",
    "print(finance_condo_updated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finance_condo_updated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbl_mappings.bbl_finance.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtm_cols_to_keep = ['unit_bbl', 'condo_boro', 'condo_numb']\n",
    "pluto_cols_to_keep = ['bbl', 'block', 'borocode', 'condono']\n",
    "\n",
    "finance_condos_only = pd.merge(queens_finance, queens_dtm[dtm_cols_to_keep],\n",
    "    how='inner', left_on=['bbl'], right_on=['unit_bbl'])\n",
    "\n",
    "# for condos: finance.bbl == finance_condos_only.unit_bbl\n",
    "#             finance_condos_only.bbl_pluto == pluto.bbl\n",
    "finance_condos_only = pd.merge(queens_pluto[pluto_cols_to_keep],\n",
    "    finance_condos_only, how='inner',\n",
    "    left_on=['borocode', 'block', 'condono'],\n",
    "    right_on=['condo_boro', 'block', 'condo_numb'],\n",
    "    suffixes=['_pluto', '_finance'])\n",
    "\n",
    "finance_condos_only = finance_condos_only[\n",
    "        ['bbl_pluto', 'bbl_finance']].drop_duplicates()\n",
    "         # duplicates only if a bbl is listed in multiple years\n",
    "finance_condos_only = finance_condos_only.loc[lambda df:\n",
    "        np.floor(df.bbl_pluto / 1e4) == np.floor(df.bbl_finance / 1e4)]\n",
    "\n",
    "# get a list of bbls that are not condos (same in pluto and finance)\n",
    "standard_bbls = list(set(queens_finance.bbl).difference(\n",
    "                    set(finance_condos_only.bbl_finance)))\n",
    "# combine condo bbls that differ with standard bbls that are the same\n",
    "bbl_mappings = finance_condos_only.append(pd.DataFrame.from_dict(\n",
    "    {'bbl_pluto': standard_bbls, 'bbl_finance': standard_bbls}\n",
    "))\n",
    "bbl_mappings = bbl_mappings.reset_index(drop = True)\n",
    "\n",
    "finance_condo_updated = pd.merge(queens_finance, bbl_mappings,\n",
    "    how='left', left_on='bbl', right_on='bbl_finance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finance condo updated: remove bbl/block/bbl_finance\n",
    "# retain only bbl_pluto to match with pluto.bbl in merge\n",
    "finance_condo_updated = finance_condo_updated.drop(\n",
    "    ['block', 'bbl', 'bbl_finance'], axis=1)\n",
    "\n",
    "# Remove duplicate bbls by returning only the most recent sales data\n",
    "# for each BBL and year\n",
    "finance_condo_updated = finance_condo_updated.reset_index()\n",
    "finance_condo_updated[\"sale_year\"] = [d.year for d in\n",
    "    finance_condo_updated.sale_date]\n",
    "grouped = finance_condo_updated.groupby(['bbl_pluto', 'sale_year'])\n",
    "max_idx_by_bbl = grouped['sale_price'].idxmax().values\n",
    "finance_condo_updated = finance_condo_updated.loc[max_idx_by_bbl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_finance_raw = pd.DataFrame()\n",
    "data_dir = \"data/finance_sales\"\n",
    "years = list(range(2003, 2017))\n",
    "boros = ['queens']\n",
    "\n",
    "for year in years:\n",
    "        for borough in boros:\n",
    "            print(\"Pulling Finance data for {}_{}\".format(year, borough))\n",
    "            boro_year = mpf.read_in_boro_year_data(borough, year, data_dir)\n",
    "            queens_finance_raw = queens_finance_raw.append(boro_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(finance_condos_only.shape)\n",
    "print(finance_condos_only.drop_duplicates().shape)\n",
    "print(finance_condos_only.drop_duplicates('bbl_finance').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(bbl_mappings.bbl_finance.duplicated(keep=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(finance_condo_updated.shape)\n",
    "print(finance_condo_updated.drop_duplicates().shape)\n",
    "print(finance_condo_updated.drop_duplicates(['bbl_pluto', 'sale_year']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finance_condo_updated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queens_pluto.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings = pd.merge(queens_pluto, finance_condo_updated, how='right',\n",
    "        left_on='bbl', right_on = 'bbl_pluto',\n",
    "        suffixes=['_pluto', '_finance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buildings[\"price_per_sqft\"] = buildings.sale_price.astype('float64') / buildings.gross_sqft_pluto\n",
    "buildings = buildings.loc[ buildings.price_per_sqft.notnull()]\n",
    "buildings = buildings.loc[ buildings.price_per_sqft > 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all(buildings.bbl == buildings.bbl_pluto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'merge_pluto_finance_new' from '/Users/jacqueline/Desktop/reveal-estate/merge_pluto_finance_new.py'>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import merge_pluto_finance_new as mpf\n",
    "from importlib import reload\n",
    "reload(mpf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boros = ['all']\n",
    "years = ['all']\n",
    "if years == [\"all\"]:\n",
    "    years = list(range(2003, 2017))\n",
    "if boros == [\"all\"]:\n",
    "    boros = [\"manhattan\", \"brooklyn\", \"queens\", \"bronx\", \"statenisland\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to lowercase and remove spaces in borough names\n",
    "boros = [\"\".join(boro.lower().split()) for boro in boros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting PLUTO data for: ['manhattan', 'brooklyn', 'queens', 'bronx', 'statenisland']\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting PLUTO data for: {}\".format(boros))\n",
    "pluto = mpf.read_in_pluto(boros)\n",
    "print(\"Getting Finance data for: {} and {}\".format(boros, years))\n",
    "finance = mpf.read_in_finance(boros, years)\n",
    "print(\"Getting DTM Condo Unit data for: {}\".format(boros))\n",
    "dtm = mpf.read_in_dtm(boros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pluto = mpf.read_in_pluto(boros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condo_boro    float64\n",
       "condo_numb      int64\n",
       "unit_block      int64\n",
       "unit_lot        int64\n",
       "unit_bbl        int64\n",
       "unit_desig     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "borough              object\n",
       "block                 int64\n",
       "schooldist          float64\n",
       "council             float64\n",
       "zipcode             float64\n",
       "ltdheight            object\n",
       "splitzone            object\n",
       "bldgclass            object\n",
       "landuse             float64\n",
       "easements             int64\n",
       "ownertype            object\n",
       "comarea             float64\n",
       "resarea             float64\n",
       "numbldgs            float64\n",
       "numfloors           float64\n",
       "unitsres            float64\n",
       "unitstotal          float64\n",
       "lotfront            float64\n",
       "lotdepth            float64\n",
       "bldgfront           float64\n",
       "bldgdepth           float64\n",
       "proxcode            float64\n",
       "irrlotcode           object\n",
       "lottype             float64\n",
       "bsmtcode              int64\n",
       "yearbuilt           float64\n",
       "builtcode            object\n",
       "histdist              int64\n",
       "landmark              int64\n",
       "borocode              int64\n",
       "bbl                   int64\n",
       "condono               int64\n",
       "xcoord              float64\n",
       "ycoord              float64\n",
       "zonemap              object\n",
       "latitude            float64\n",
       "longitude           float64\n",
       "gross_sqft_pluto    float64\n",
       "garage                int64\n",
       "extension             int64\n",
       "countalter            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluto.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N      314365\n",
       "Y       10039\n",
       "NaN       152\n",
       "Name: splitzone, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluto_raw_queens.splitzone.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N      275303\n",
       "Y       49101\n",
       "NaN       152\n",
       "Name: irrlotcode, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluto_raw_queens.irrlotcode.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN      42286\n",
       "LH-1A      812\n",
       "LH-1        60\n",
       "Name: ltdheight, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluto_raw_manhattan.ltdheight.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
